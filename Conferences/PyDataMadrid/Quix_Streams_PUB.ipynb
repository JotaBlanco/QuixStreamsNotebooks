{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JotaBlanco/QuixStreamsNotebooks/blob/main/Conferences/PyDataMadrid/Quix_Streams_PUB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Quix Streams\n",
        "Just use pip install to download the Quix Streams library. \n",
        "\n",
        "[Quix Streams](https://github.com/quixio/quix-streams) is an open source Python library for processing streaming data. It’s aimed at people who work with time-series data streams — from developers and ML engineers to data scientists and data engineers."
      ],
      "metadata": {
        "id": "xIaLLhNZeuTK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM8eAVmnepVy"
      },
      "outputs": [],
      "source": [
        "! pip install quixstreams"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the libraries\n",
        "We will be using mainly pandas, quix, matplotlib and seaborn."
      ],
      "metadata": {
        "id": "qgkdL-bxe1EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import quixstreams as qx"
      ],
      "metadata": {
        "id": "TPppt6CqezXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Create client\n",
        "Let's start by creating a Quix client that we'll use to publish and subscribe to Kafka topics."
      ],
      "metadata": {
        "id": "TCsYuP_ciF04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiating Quix managed token, but it could be your own kafka\n",
        "token = 'sdk-296f2b9decff4770a525ff7d8855a78d'\n",
        "client = qx.QuixStreamingClient(token)\n",
        "client"
      ],
      "metadata": {
        "id": "IIaACdc_e5MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Producer client\n",
        "To publish data to one topic, we will need to create a producer client pointing to that topic."
      ],
      "metadata": {
        "id": "tmIXVN2ow7e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_name = \"test-topic\"\n",
        "topic_producer = client.get_topic_producer(topic_name)\n",
        "topic_producer"
      ],
      "metadata": {
        "id": "4shtFNDUo6Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Streams\n",
        "Streams are ways to distribute the messages load into a topic very efficiently, allowing escalation whilst ensuring chronolofical order. Streams are to topics what road lines are to highways. \n",
        "We don't need many streams yet, but let's see how they are created:"
      ],
      "metadata": {
        "id": "_prbdjkpyLU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stream_id = \"test-stream_1\"\n",
        "test_stream_1 = topic_producer.create_stream(stream_id)\n",
        "test_stream_1"
      ],
      "metadata": {
        "id": "f7laCKv1xEe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream_id = \"test-stream_2\"\n",
        "test_stream_2 = topic_producer.create_stream(stream_id)\n",
        "test_stream_2"
      ],
      "metadata": {
        "id": "NqaooLQXygNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - Publish data to the topic\n",
        "Let's publish each of the data messages created to one stream now:"
      ],
      "metadata": {
        "id": "ZhouyK-BzDWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "YE5NZey1AXR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    \"Timestamp\": [pd.Timestamp.now()],\n",
        "    \"Param A\": [random.randint(10, 20)],\n",
        "    \"Param B\": [random.randint(0, 10)]\n",
        "})\n",
        "test_stream_1.timeseries.publish(df)"
      ],
      "metadata": {
        "id": "duFPUvR2AKBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    \"Timestamp\": [pd.Timestamp.now()],\n",
        "    \"Param A\": [random.randint(10, 20)],\n",
        "    \"Param B\": [random.randint(0, 10)]\n",
        "})\n",
        "test_stream_2.timeseries.publish(df)"
      ],
      "metadata": {
        "id": "aatFBlC5JnR_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}