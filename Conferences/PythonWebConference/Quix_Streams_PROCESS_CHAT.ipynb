{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JotaBlanco/QuixStreamsNotebooks/blob/main/Conferences/PythonWebConference/Quix_Streams_PROCESS_CHAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Quix Streams\n",
        "Just use pip install to download the Quix Streams library. \n",
        "\n",
        "[Quix Streams](https://github.com/quixio/quix-streams) is an open source Python library for processing streaming data. It’s aimed at people who work with time-series data streams — from developers and ML engineers to data scientists and data engineers."
      ],
      "metadata": {
        "id": "xIaLLhNZeuTK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM8eAVmnepVy"
      },
      "outputs": [],
      "source": [
        "! pip install quixstreams"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the libraries\n",
        "We will be using mainly pandas, quix, matplotlib and seaborn."
      ],
      "metadata": {
        "id": "qgkdL-bxe1EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import quixstreams as qx"
      ],
      "metadata": {
        "id": "TPppt6CqezXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Create client\n",
        "Let's start by creating a Quix client that we'll use to publish and subscribe to Kafka topics."
      ],
      "metadata": {
        "id": "TCsYuP_ciF04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiating Quix managed token, but it could be your own kafka\n",
        "token = 'sdk-296f2b9decff4770a525ff7d8855a78d'\n",
        "client = qx.QuixStreamingClient(token)\n",
        "client"
      ],
      "metadata": {
        "id": "IIaACdc_e5MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Clients\n",
        "Create producer and consumer clients"
      ],
      "metadata": {
        "id": "tmIXVN2ow7e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_name = \"chat-messages-enriched\"\n",
        "topic_producer = client.get_topic_producer(topic_name)\n",
        "topic_producer"
      ],
      "metadata": {
        "id": "4shtFNDUo6Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream_id = \"python web conference\"\n",
        "stream_out = topic_producer.get_or_create_stream(stream_id)\n",
        "stream_out"
      ],
      "metadata": {
        "id": "TRyARMKAXnpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_name = \"chat-messages\"\n",
        "topic_consumer = client.get_topic_consumer(topic_name)\n",
        "topic_consumer"
      ],
      "metadata": {
        "id": "avEJAgNPcRJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Listen to some data\n",
        "Let's listen to some data"
      ],
      "metadata": {
        "id": "ZhouyK-BzDWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.DataFrame()\n",
        "\n",
        "def on_stream_received_handler(stream_received: qx.StreamConsumer):\n",
        "  stream_received.timeseries.on_dataframe_received = on_timeseries_data_received_handler\n",
        "\n",
        "def on_timeseries_data_received_handler(stream: qx.StreamConsumer, df_i: pd.DataFrame):\n",
        "  global df\n",
        "  df = df.append(df_i)\n",
        "  print(\"Data from stream \" + stream.stream_id)\n",
        "  display(df_i)\n",
        "\n",
        "topic_consumer = client.get_topic_consumer(topic_name)\n",
        "topic_consumer.on_stream_received = on_stream_received_handler\n",
        "qx.App.run()"
      ],
      "metadata": {
        "id": "pHNFKRBeJ-xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "KOkfsleDFqBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Process data with Hugging Face"
      ],
      "metadata": {
        "id": "j67WTZU2dYpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "id": "NvjifpOdif_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "o9j_Y-jFigDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_model = pipeline(model='siebert/sentiment-roberta-large-english')"
      ],
      "metadata": {
        "id": "hbpNVj5BigGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(pipeline_model([\"This is analysing text\", \"Two messages\"]))"
      ],
      "metadata": {
        "id": "nUq2jEmoikPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 - Processing without state"
      ],
      "metadata": {
        "id": "JoQ3v-x1rQov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_producer = client.get_topic_producer(\"chat-messages-enriched\")\n",
        "stream_out = topic_producer.get_or_create_stream(\"python web conference\")\n",
        "\n",
        "def on_stream_received_handler(stream_received: qx.StreamConsumer):\n",
        "  stream_received.timeseries.on_dataframe_received = on_timeseries_data_received_handler\n",
        "\n",
        "def on_timeseries_data_received_handler(stream_in: qx.StreamConsumer, df: pd.DataFrame):\n",
        "  \n",
        "  # Add predictions\n",
        "  df_prediction = pd.DataFrame(pipeline_model(list(df[\"chat-message\"])))\n",
        "  df = pd.concat([df, df_prediction], axis=1)\n",
        "  \n",
        "  # Sentiment column\n",
        "  df[\"sentiment\"] = df[\"score\"]\n",
        "  filter_negative = df[\"label\"] == \"NEGATIVE\"\n",
        "  df.loc[filter_negative, \"sentiment\"] = -df.loc[filter_negative, \"score\"]\n",
        "  \n",
        "  # Average\n",
        "  #df[\"average_sentiment\"] = df[\"sentiment\"]\n",
        "  display(df)\n",
        "  stream_out.timeseries.publish(df)\n",
        "\n",
        "topic_consumer = client.get_topic_consumer(\"chat-messages\")\n",
        "topic_consumer.on_stream_received = on_stream_received_handler\n",
        "qx.App.run()"
      ],
      "metadata": {
        "id": "NCO90coxdX4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 - Processing with state"
      ],
      "metadata": {
        "id": "hSxexsg1rm-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_producer = client.get_topic_producer(\"chat-messages-enriched\")\n",
        "stream_out = topic_producer.get_or_create_stream(\"python web conference\")\n",
        "\n",
        "last_X_sent = []\n",
        "\n",
        "def on_stream_received_handler(stream_received: qx.StreamConsumer):\n",
        "  stream_received.timeseries.on_dataframe_received = on_timeseries_data_received_handler\n",
        "\n",
        "def on_timeseries_data_received_handler(stream_in: qx.StreamConsumer, df: pd.DataFrame):\n",
        "  global last_X_sent\n",
        "\n",
        "  # Add predictions\n",
        "  df_prediction = pd.DataFrame(pipeline_model(list(df[\"chat-message\"])))\n",
        "  df = pd.concat([df, df_prediction], axis=1)\n",
        "  \n",
        "  # Sentiment column\n",
        "  df[\"sentiment\"] = df[\"score\"]\n",
        "  filter_negative = df[\"label\"] == \"NEGATIVE\"\n",
        "  df.loc[filter_negative, \"sentiment\"] = -df.loc[filter_negative, \"score\"]\n",
        "  \n",
        "  # Average\n",
        "  last_X_sent = last_X_sent + list(df[\"sentiment\"])\n",
        "  last_X_sent = last_X_sent[-5:]\n",
        "  df[\"average_sentiment\"] = sum(last_X_sent)/len(last_X_sent)\n",
        "  display(df)\n",
        "\n",
        "  df[\"Timestamp\"] = pd.Timestamp.now()\n",
        "  stream_out.timeseries.publish(df)\n",
        "\n",
        "topic_consumer = client.get_topic_consumer(\"chat-messages\")\n",
        "topic_consumer.on_stream_received = on_stream_received_handler\n",
        "qx.App.run()"
      ],
      "metadata": {
        "id": "fWhWnjNUy-7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AAiXhHQ8oL72"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}