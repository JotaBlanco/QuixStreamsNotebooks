{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JotaBlanco/QuixStreamsNotebooks/blob/main/Conferences/BerlinTimeseriesMeetup/Quix_Streams_SUB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Quix Streams\n",
        "Just use pip install to download the Quix Streams library. \n",
        "\n",
        "[Quix Streams](https://github.com/quixio/quix-streams) is an open source Python library for processing streaming data. It’s aimed at people who work with time-series data streams — from developers and ML engineers to data scientists and data engineers."
      ],
      "metadata": {
        "id": "xIaLLhNZeuTK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM8eAVmnepVy"
      },
      "outputs": [],
      "source": [
        "! pip install quixstreams"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the libraries\n",
        "We will be using mainly pandas, quix, matplotlib and seaborn."
      ],
      "metadata": {
        "id": "qgkdL-bxe1EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import quixstreams as qx"
      ],
      "metadata": {
        "id": "TPppt6CqezXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Create client\n",
        "Let's start by creating a Quix client that we'll use to publish and subscribe to Kafka topics."
      ],
      "metadata": {
        "id": "TCsYuP_ciF04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token = 'sdk-296f2b9decff4770a525ff7d8855a78d'\n",
        "client = qx.QuixStreamingClient(token)\n",
        "client"
      ],
      "metadata": {
        "id": "IIaACdc_e5MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Consumer client\n",
        "To suscribe to data from one topic, we will need to create a consumer client pointing to that topic."
      ],
      "metadata": {
        "id": "tmIXVN2ow7e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_name = \"test-topic\"\n",
        "topic_consumer = client.get_topic_consumer(topic_name)\n",
        "topic_consumer"
      ],
      "metadata": {
        "id": "4shtFNDUo6Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Suscribing to topics\n",
        "Once you have the TopicConsumer instance you can start receiving data. These are the steps:"
      ],
      "metadata": {
        "id": "_prbdjkpyLU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 - Subscribing to streams\n",
        "For each stream received, the TopicConsumer will execute the callback you define. This callback will be invoked every time you receive a new stream."
      ],
      "metadata": {
        "id": "SmkO2S1LgubH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def on_stream_received_handler(stream_received: qx.StreamConsumer):\n",
        "  \"\"\"\n",
        "  My callback to new streams received is defined here\n",
        "  \"\"\"\n",
        "  print(\"New stream just received: \" + stream_received.stream_id)\n",
        "\n",
        "topic_consumer = client.get_topic_consumer(topic_name)\n",
        "topic_consumer.on_stream_received = on_stream_received_handler\n",
        "qx.App.run()"
      ],
      "metadata": {
        "id": "f7laCKv1xEe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 - Subscribing to Timeseries data\n",
        "You can subscribe to time-series data from streams using the on_data_received callback of the StreamConsumer instance."
      ],
      "metadata": {
        "id": "c6VfshI0hzz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 - qx.TimeseriesData\n",
        "This is how you read the data in the standard TimeseriesData format:"
      ],
      "metadata": {
        "id": "3vXgknjgzMuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def on_stream_received_handler(stream_received: qx.StreamConsumer):\n",
        "    stream_received.timeseries.on_data_received = on_timeseries_data_received_handler\n",
        "\n",
        "def on_timeseries_data_received_handler(stream: qx.StreamConsumer, data: qx.TimeseriesData):\n",
        "  print(\"Data from stream \" + stream.stream_id)\n",
        "  with data:\n",
        "    print(data)\n",
        "\n",
        "topic_consumer = client.get_topic_consumer(topic_name)\n",
        "topic_consumer.on_stream_received = on_stream_received_handler\n",
        "qx.App.run()"
      ],
      "metadata": {
        "id": "rA7tKDY1iBrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 - pd.DataFrame\n",
        "This is how you read the data in pandas dataframe format."
      ],
      "metadata": {
        "id": "iID7_56JzvMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def on_stream_received_handler(stream_received: qx.StreamConsumer):\n",
        "  stream_received.timeseries.on_dataframe_received = on_timeseries_data_received_handler\n",
        "\n",
        "def on_timeseries_data_received_handler(stream: qx.StreamConsumer, df: pd.DataFrame):\n",
        "  print(\"Data from stream \" + stream.stream_id)\n",
        "  display(df)\n",
        "\n",
        "topic_consumer = client.get_topic_consumer(topic_name)\n",
        "topic_consumer.on_stream_received = on_stream_received_handler\n",
        "qx.App.run()"
      ],
      "metadata": {
        "id": "JBqTqPUiyiwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.DataFrame()\n",
        "\n",
        "def on_stream_received_handler(stream_received: qx.StreamConsumer):\n",
        "  stream_received.timeseries.on_dataframe_received = on_timeseries_data_received_handler\n",
        "\n",
        "def on_timeseries_data_received_handler(stream: qx.StreamConsumer, df_i: pd.DataFrame):\n",
        "  global df\n",
        "  df = df.append(df_i)\n",
        "  print(\"Data from stream \" + stream.stream_id)\n",
        "  display(df_i)\n",
        "\n",
        "topic_consumer = client.get_topic_consumer(topic_name)\n",
        "topic_consumer.on_stream_received = on_stream_received_handler\n",
        "qx.App.run()"
      ],
      "metadata": {
        "id": "4Hdi4rie0jio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "PH03d2fz0jmb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}