{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JotaBlanco/QuixStreamsNotebooks/blob/main/Conferences/BerlinTimeseriesMeetup/Quix_Streams_PUB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Quix Streams\n",
        "Just use pip install to download the Quix Streams library. \n",
        "\n",
        "[Quix Streams](https://github.com/quixio/quix-streams) is an open source Python library for processing streaming data. It’s aimed at people who work with time-series data streams — from developers and ML engineers to data scientists and data engineers."
      ],
      "metadata": {
        "id": "xIaLLhNZeuTK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM8eAVmnepVy"
      },
      "outputs": [],
      "source": [
        "! pip install quixstreams"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the libraries\n",
        "We will be using mainly pandas, quix, matplotlib and seaborn."
      ],
      "metadata": {
        "id": "qgkdL-bxe1EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import quixstreams as qx"
      ],
      "metadata": {
        "id": "TPppt6CqezXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Create client\n",
        "Let's start by creating a Quix client that we'll use to publish and subscribe to Kafka topics."
      ],
      "metadata": {
        "id": "TCsYuP_ciF04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiating Quix managed token, but it could be your own kafka\n",
        "token = 'sdk-296f2b9decff4770a525ff7d8855a78d'\n",
        "client = qx.QuixStreamingClient(token)\n",
        "client"
      ],
      "metadata": {
        "id": "IIaACdc_e5MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Producer client\n",
        "To publish data to one topic, we will need to create a producer client pointing to that topic."
      ],
      "metadata": {
        "id": "tmIXVN2ow7e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_name = \"test-topic\"\n",
        "topic_producer = client.get_topic_producer(topic_name)\n",
        "topic_producer"
      ],
      "metadata": {
        "id": "4shtFNDUo6Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Streams\n",
        "Streams are ways to distribute the messages load into a topic very efficiently, allowing escalation whilst ensuring chronolofical order. Streams are to topics what road lines are to highways. \n",
        "We don't need many streams yet, but let's see how they are created:"
      ],
      "metadata": {
        "id": "_prbdjkpyLU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stream_id = \"test-stream_1\"\n",
        "test_stream_1 = topic_producer.create_stream(stream_id)\n",
        "test_stream_1"
      ],
      "metadata": {
        "id": "f7laCKv1xEe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream_id = \"test-stream_2\"\n",
        "test_stream_2 = topic_producer.create_stream(stream_id)\n",
        "test_stream_2"
      ],
      "metadata": {
        "id": "NqaooLQXygNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can add properties to streams, like names and metadata."
      ],
      "metadata": {
        "id": "WgVcZSxoyk7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_stream_1.properties.name = \"Tutorial Test Stream 1\"\n",
        "test_stream_1.properties.metadata[\"Test Number\"] = \"1\"\n",
        "test_stream_2.properties.name = \"Tutorial Test Stream 2\"\n",
        "test_stream_2.properties.metadata[\"Test Number\"] = \"2\""
      ],
      "metadata": {
        "id": "JBqTqPUiyiwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Data format\n",
        "There are two data formats Quix Stream can use to publish data to topics:"
      ],
      "metadata": {
        "id": "tkWGBTntypzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 TimeseriesData\n",
        "TimeseriesData is the formal class in Quix Streams which represents a time series data packet in memory. The format consists of a list of Timestamps with their corresponding parameter names and values for each timestamp.\n",
        "\n",
        "You should imagine a TimeseriesData as a table where the Timestamp is the first column of that table and where the parameters are the columns for the values of that table."
      ],
      "metadata": {
        "id": "pziUUpTwDyrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This dataframe follows the proper TimeseriesData format: timestamp and different parameters\n",
        "df = pd.DataFrame({\n",
        "    \"Timestamp\": [pd.Timestamp.now(), pd.Timestamp.now() + pd.Timedelta(\"5sec\")],\n",
        "    \"Param A\": [10, 20],\n",
        "    \"Column B\": [12, 9]\n",
        "})\n",
        "df"
      ],
      "metadata": {
        "id": "L_8jGMBry5u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the actual way to define a qx.TimeseriesData object for that same data\n",
        "timeseries_data = qx.TimeseriesData()\n",
        "timeseries_data.add_timestamp(pd.Timestamp.now()) \\\n",
        "                .add_value(\"Param A\", 10) \\\n",
        "                .add_value(\"Column B\", 12)\n",
        "timeseries_data.add_timestamp(pd.Timestamp.now() + pd.Timedelta(\"5sec\")) \\\n",
        "                .add_value(\"Param A\", 20) \\\n",
        "                .add_value(\"Column B\", 9)"
      ],
      "metadata": {
        "id": "LYXIM2hZy7yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversions between qx.TimeseriesData and pd.Dataframe formats are easy:"
      ],
      "metadata": {
        "id": "bNCPG7xDEpd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_data.to_dataframe()"
      ],
      "metadata": {
        "id": "CQhqmdDIFTdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qx.TimeseriesData.from_panda_dataframe(df)"
      ],
      "metadata": {
        "id": "rmFthI9aFZBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 EventData\n",
        "EventData consists of a record with a Timestamp, an EventId and an EventValue.\n",
        "\n",
        "You should imagine a list of EventData instances as a simple table of three columns where the Timestamp is the first column of that table and the EventId and EventValue are the second and third columns, as shown in the following table."
      ],
      "metadata": {
        "id": "qhnoFDqnGDFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event_data_1 = qx.EventData(\n",
        "    event_id = \"Door Open\", \n",
        "    time = pd.Timestamp.now(), \n",
        "    value = \"The front door of the house has just been open\")\n",
        "event_data_1"
      ],
      "metadata": {
        "id": "wF-JFukAGZ6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_data_2 = qx.EventData(\n",
        "    event_id = \"Door Closed\", \n",
        "    time = pd.Timestamp.now(), \n",
        "    value = \"The front door of the house is back to closed state\")\n",
        "event_data_2"
      ],
      "metadata": {
        "id": "yXdNwC0GGZ-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - Publish data to the topic\n",
        "Let's publish each of the data messages created to one stream now:"
      ],
      "metadata": {
        "id": "ZhouyK-BzDWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 TimeseriesData\n",
        "Let's see how to publish the TimeseriesData object we created earlier."
      ],
      "metadata": {
        "id": "wBOjJxFgJk6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_data"
      ],
      "metadata": {
        "id": "pHNFKRBeJ-xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Publishing it to stream 1 and stream 2\n",
        "test_stream_1.timeseries.publish(timeseries_data)\n",
        "test_stream_2.timeseries.publish(timeseries_data)"
      ],
      "metadata": {
        "id": "fWhWnjNUy-7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Also, pd.DataFrame objects can be published very simply  \n",
        "# (conversion to qx.TimeseriesData object is done automatically)\n",
        "df"
      ],
      "metadata": {
        "id": "CmcLJIssKKPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Publishing it to stream 1 and stream 2\n",
        "test_stream_1.timeseries.publish(df)\n",
        "test_stream_2.timeseries.publish(df)"
      ],
      "metadata": {
        "id": "z6usi8vrKKS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_stream_1.timeseries.publish(df)\n",
        "print(\"Sent\")"
      ],
      "metadata": {
        "id": "ziQXs8RW5A0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 EventData\n",
        "Let's now publish the EventData messages we created earlier:"
      ],
      "metadata": {
        "id": "XPnmPr3TKiTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Publishing event 1 to stream 1, and event 2 to stream 2\n",
        "test_stream_1.events.publish(event_data_1)\n",
        "test_stream_2.events.publish(event_data_2)"
      ],
      "metadata": {
        "id": "g2B4GTRKKrq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.3 - Publish random data"
      ],
      "metadata": {
        "id": "5a70dI6KADHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "YE5NZey1AXR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    \"Timestamp\": [pd.Timestamp.now()],\n",
        "    \"Param A\": [random.randint(10, 20)],\n",
        "    \"Param B\": [random.randint(0, 10)]\n",
        "})\n",
        "test_stream_1.timeseries.publish(df)"
      ],
      "metadata": {
        "id": "duFPUvR2AKBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aatFBlC5JnR_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}